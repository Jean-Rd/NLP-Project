{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "        'Quispe fundó el Movimiento Indígena Tupak Katari en 1979 y el Ejército Guerrillero Tupak Katari en 1990. Su nombre honorífico, Mallku, hace referencia al espíritu de las montañas que rodean y protegen al Pueblo, y por tanto es la fuente de vida. \"Mallku\" significa \"pico\" tanto en geografía como en jerarquía',\n",
    "       'Quispe era un acérrimo oponente del neoliberal de consenso Washington , y también estaba enérgicamente en contra de los esquemas liderados por Estados Unidos para la erradicación de la coca , que él considera que destruye una parte crítica de la cultura aymara. Estuvo muy involucrado en la Guerra del Gas de Bolivia.',\n",
    "       'Quispe realizó una campaña fallida en las elecciones presidenciales de 2005 , que vieron la victoria del indígena Evo Morales , líder del MAS (Movimiento al socialismo). Quispe fue un crítico vocal del gobierno de Morales, y lo caracterizó como un representante del \"neoliberalismo con rostro indio\"',\n",
    "       'En 1984, fue uno de los principales organizadores del Ejército Guerrillero Tupac Katari, una insurrección armada fallida contra el gobierno. Quispe fue arrestado por su participación en el movimiento el 19 de agosto de 1992.',\n",
    "       'Quispe ha trabajado para el establecimiento de una república Tawantinsuyu - que tomaría el nombre de \" Collasuyu \" - en las aymara regiones de mayoría de Bolivia. ',\n",
    "        'Quispe falleció el 19 de enero de 2021 en El Alto por un paro cardíaco . '\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tf.keras.preprocessing.text.Tokenizer(oov_token=\"<OVV>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadena = ''\n",
    "for i in text:\n",
    "    cadena += i +\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cadena.lower().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quispe fundó el movimiento indígena tupak katari en 1979 y el ejército guerrillero tupak katari en 1990. su nombre honorífico, mallku, hace referencia al espíritu de las montañas que rodean y protegen al pueblo, y por tanto es la fuente de vida. \"mallku\" significa \"pico\" tanto en geografía como en jerarquía'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OVV>': 1, 'de': 2, 'en': 3, 'el': 4, 'quispe': 5, 'del': 6, 'la': 7, 'y': 8, 'que': 9, 'por': 10, 'un': 11, 'una': 12, 'movimiento': 13, 'katari': 14, 'al': 15, 'las': 16, 'fue': 17, 'indígena': 18, 'tupak': 19, 'ejército': 20, 'guerrillero': 21, 'su': 22, 'nombre': 23, 'mallku': 24, 'tanto': 25, 'como': 26, 'contra': 27, 'los': 28, 'para': 29, 'aymara': 30, 'bolivia': 31, 'fallida': 32, 'morales': 33, 'gobierno': 34, '19': 35, 'fundó': 36, '1979': 37, '1990': 38, 'honorífico': 39, 'hace': 40, 'referencia': 41, 'espíritu': 42, 'montañas': 43, 'rodean': 44, 'protegen': 45, 'pueblo': 46, 'es': 47, 'fuente': 48, 'vida': 49, 'significa': 50, 'pico': 51, 'geografía': 52, 'jerarquía': 53, 'era': 54, 'acérrimo': 55, 'oponente': 56, 'neoliberal': 57, 'consenso': 58, 'washington': 59, 'también': 60, 'estaba': 61, 'enérgicamente': 62, 'esquemas': 63, 'liderados': 64, 'estados': 65, 'unidos': 66, 'erradicación': 67, 'coca': 68, 'él': 69, 'considera': 70, 'destruye': 71, 'parte': 72, 'crítica': 73, 'cultura': 74, 'estuvo': 75, 'muy': 76, 'involucrado': 77, 'guerra': 78, 'gas': 79, 'realizó': 80, 'campaña': 81, 'elecciones': 82, 'presidenciales': 83, '2005': 84, 'vieron': 85, 'victoria': 86, 'evo': 87, 'líder': 88, 'mas': 89, 'socialismo': 90, 'crítico': 91, 'vocal': 92, 'lo': 93, 'caracterizó': 94, 'representante': 95, 'neoliberalismo': 96, 'con': 97, 'rostro': 98, 'indio': 99, '1984': 100, 'uno': 101, 'principales': 102, 'organizadores': 103, 'tupac': 104, 'insurrección': 105, 'armada': 106, 'arrestado': 107, 'participación': 108, 'agosto': 109, '1992': 110, 'ha': 111, 'trabajado': 112, 'establecimiento': 113, 'república': 114, 'tawantinsuyu': 115, 'tomaría': 116, 'collasuyu': 117, 'regiones': 118, 'mayoría': 119, 'falleció': 120, 'enero': 121, '2021': 122, 'alto': 123, 'paro': 124, 'cardíaco': 125}\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "print(token.word_index); print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for i in corpus:\n",
    "    token_list = token.texts_to_sequences([i])[0]\n",
    "    #print(token_list)\n",
    "    # Tokenizamos las palabras\n",
    "    for j in range(1, len(token_list)):\n",
    "        # aca agremamos palabras por palabras para que el algoritmo aprenda a predecir la sig palabra\n",
    "        n_gram_sequence = token_list[:j+1]\n",
    "        #print(n_gram_sequence)\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence = max([len(i) for i in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_padd = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_padd[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = input_padd[:,:-1], input_padd[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5, 36]),\n",
       " 4)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[1,:], labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "31\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "print(token.word_index['mallku'])\n",
    "print(token.word_index['bolivia'])\n",
    "print(token.word_index['enero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  5, 36,  4, 13, 18, 19, 14]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[6], ys[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(total_words, 64, input_length=max_sequence-1))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "model.add(tf.keras.layers.Dense(total_words, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.00001, momentum=0.9, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 104ms/step - loss: 0.0367 - accuracy: 0.9886\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0283 - accuracy: 0.9852\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0320 - accuracy: 0.9829\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0408 - accuracy: 0.9862\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0400 - accuracy: 0.9795\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0352 - accuracy: 0.9896\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0489 - accuracy: 0.9731\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0248 - accuracy: 0.9886\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0407 - accuracy: 0.9795\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0237 - accuracy: 0.9877\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0190 - accuracy: 0.9918\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0288 - accuracy: 0.9849\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0312 - accuracy: 0.9884\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0539 - accuracy: 0.9711\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0462 - accuracy: 0.9787\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0483 - accuracy: 0.9738\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0297 - accuracy: 0.9851\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0488 - accuracy: 0.9810\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0282 - accuracy: 0.9862\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0372 - accuracy: 0.9884\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0433 - accuracy: 0.9847\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0541 - accuracy: 0.9741\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0219 - accuracy: 0.9903\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0236 - accuracy: 0.9879\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0475 - accuracy: 0.9740\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0435 - accuracy: 0.9805\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0266 - accuracy: 0.9864\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 101ms/step - loss: 0.0435 - accuracy: 0.9749\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0482 - accuracy: 0.9777\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0421 - accuracy: 0.9784\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0393 - accuracy: 0.9780\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0227 - accuracy: 0.9916\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0382 - accuracy: 0.9823\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0608 - accuracy: 0.9668\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0497 - accuracy: 0.9810\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0235 - accuracy: 0.9878\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0440 - accuracy: 0.9772\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0609 - accuracy: 0.9733\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0418 - accuracy: 0.9855\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0462 - accuracy: 0.9827\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0248 - accuracy: 0.9897\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0403 - accuracy: 0.9780\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0432 - accuracy: 0.9806\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0555 - accuracy: 0.9701\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0453 - accuracy: 0.9756\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0499 - accuracy: 0.9810\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0700 - accuracy: 0.9681\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0313 - accuracy: 0.9920\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0367 - accuracy: 0.9831\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0545 - accuracy: 0.9779\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0250 - accuracy: 0.9902\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0595 - accuracy: 0.9711\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0368 - accuracy: 0.9831\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0508 - accuracy: 0.9766\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0386 - accuracy: 0.9802\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0165 - accuracy: 0.9933\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0541 - accuracy: 0.9779\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0433 - accuracy: 0.9759\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0298 - accuracy: 0.9890\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0488 - accuracy: 0.9784\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0337 - accuracy: 0.9812\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0600 - accuracy: 0.9750\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0477 - accuracy: 0.9784\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0530 - accuracy: 0.9725\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0329 - accuracy: 0.9854\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0241 - accuracy: 0.9909\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0546 - accuracy: 0.9784\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0356 - accuracy: 0.9834\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0504 - accuracy: 0.9772\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0370 - accuracy: 0.9828\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0367 - accuracy: 0.9854\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0345 - accuracy: 0.9819\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0346 - accuracy: 0.9830\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0612 - accuracy: 0.9668\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0499 - accuracy: 0.9753\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.0271 - accuracy: 0.9866\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0392 - accuracy: 0.9789\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0207 - accuracy: 0.9894\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.0385 - accuracy: 0.98420s - loss: 0.0384 - accuracy: 0.98\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0463 - accuracy: 0.9745\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.0312 - accuracy: 0.9854\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0317 - accuracy: 0.9860\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0360 - accuracy: 0.9823\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0431 - accuracy: 0.9845\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0333 - accuracy: 0.9873\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 1s 103ms/step - loss: 0.0284 - accuracy: 0.9845\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0389 - accuracy: 0.9813\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 0.0361 - accuracy: 0.9836\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 0.0337 - accuracy: 0.9904\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.0332 - accuracy: 0.9821\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0300 - accuracy: 0.9849\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 1s 102ms/step - loss: 0.0473 - accuracy: 0.9764\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.0249 - accuracy: 0.9881\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0428 - accuracy: 0.9816\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0386 - accuracy: 0.9827\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0401 - accuracy: 0.9777\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0362 - accuracy: 0.9813\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0441 - accuracy: 0.9756\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 0.0487 - accuracy: 0.9780\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0270 - accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xs, ys, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18e2a634c10>]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el mallku murio en :las:elecciones:de:consenso:washington:y:también:estaba:enérgicamente:en:contra:de:los:esquemas:liderados:por:estados:unidos:para:la:erradicación:de:la:coca:que:él:considera:que:destruye:una:parte:crítica:de:la:cultura:aymara:estuvo:muy:involucrado:en:la:guerra:del:gas:de:bolivia:bolivia:bolivia:bolivia:tanto\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'el mallku murio en '\n",
    "next_word =50\n",
    "\n",
    "for _ in range(next_word):\n",
    "    token_list = token.texts_to_sequences([seed_text])[0]\n",
    "    token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence-1, padding='pre')\n",
    "    predict = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = ''\n",
    "    \n",
    "    for word, index in token.word_index.items():\n",
    "        if index == predict:\n",
    "            output_word = word\n",
    "            break\n",
    "            \n",
    "    seed_text += \":\"+ output_word\n",
    "    \n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
